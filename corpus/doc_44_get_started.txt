You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, which you can convert to a string or Message object, depending on whether you want to use the formatted value as input to an llm or chat model.chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])# get a chat completion from the formatted messageschat_prompt.format_prompt(input_language="English", output_language="French", text="I love programming.").to_messages()    [SystemMessage(content='You are a helpful assistant that translates English to French.', additional_kwargs={}),     HumanMessage(content='I love programming.', additional_kwargs={})]Edit this pagePreviousPromptsNextConnecting to a Feature StoreWhat is a prompt template?CommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.